Architecture: "drought-lstm"

Seed: 42

Setting: "drought"

Logger:
    save_dir: "experiments/"

Checkpointer:
    save_top_k: 1
    save_last: True
    every_n_epochs: 1
    monitor: "RMSE_drought"

Trainer:
    devices: 1 #6
    #accelerator: 'auto' #automatically chooses between gpu and cpu
    strategy: 'ddp' #if this is on, no need to specifiy accelerator in pl.Trainer()
    #deterministic: True
    log_every_n_steps: 32
    #profiler: 'advanced'
    fast_dev_run: False
    #log_gpu_memory: 'all'
    #weights_summary: 'full'
    max_epochs: 100
    #limit_train_batches: 32
    #limit_val_batches: 32
    gradient_clip_val: 1
    #val_check_interval: 0.01 #val after fraction of training epoch
    check_val_every_n_epoch: 1
    num_sanity_val_steps: 0
    #overfit_batches: 0.0
  
Data:
    base_dir: "/data/scratch/selene/" #where data is stored
    test_track: "ood"
    train_batch_size: 64
    val_batch_size: 64
    test_batch_size: 64
    num_workers: 4
    val_pct: 0.10
    #dl_cloudmask: True

Task:
    loss:
        name: "L2NDVILoss"
        ndvi_pred_idx: 0
        ndvi_targ_idx: 5
    context_length: 54 #(9 months)
    target_length: 18 #(3 months)
    optimization:
        optimizer:
            - 
                name: Adam
                args: 
                    betas: [0.8, 0.999] 
                    lr: 0.0001
                lr_per_sample: 0.000001
        lr_shedule:
            -
                name: MultiStepLR
                args:
                    milestones: [160,190] #[2, 20, 50, 90]
                    gamma: 0.1
    n_log_batches: 2
    compute_metric_on_test: True

Model:
    input_dim: 74 #number of input features
    hidden_dim: 64 #number of nodes in hidden layers
    num_layers: 10 #number of hidden layers
    target_length: 18
